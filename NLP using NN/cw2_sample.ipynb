{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework Assignment 2: Measuring Sentence Similarity\n",
    "The purpose of this file is to help you develop your model. You **DON'T** need to submit this file. In the end, you should submit\n",
    "* A report, summarising all your findings and analyses.\n",
    "* For task 1 (MLP-based model), submit two files: **test_mlp.ipynb** which includes the impelementation, and **best_mlp.state_dict**, which is the saved MLP weights.\n",
    "* For task 2 (CNN- or RNN-based model), submit two files: **test_cnn.ipynb** (if you developed a RNN model, change cnn to rnn) which includes the impelementation, and **best_cnn.state_dict**, which is the saved CNN/RNN weights.\n",
    "* For task 3 (additional models), similarly, submit the implementation as well as the saved weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer,LancasterStemmer\n",
    "from nltk import ConditionalFreqDist,FreqDist,pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sent1</th>\n",
       "      <th>Sent2</th>\n",
       "      <th>SimScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S., EU Widen Sanctions On Russia</td>\n",
       "      <td>U.S., EU Boost Sanctions On Russia</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The lawyers advised the judges .</td>\n",
       "      <td>The lawyers advised the judges behind the acto...</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Man kills 4 in Calif. before police shoot him ...</td>\n",
       "      <td>Police: Gunman killed 6 in California shootings</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Someone is playing a piano.</td>\n",
       "      <td>A man is playing a guitar.</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In an E-mail statement to the Knoxville News S...</td>\n",
       "      <td>I am not giving any consideration to resignati...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11493</th>\n",
       "      <td>11493</td>\n",
       "      <td>A man is playing piano.</td>\n",
       "      <td>A man is laying on the ground.</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>11494</td>\n",
       "      <td>The doctors resigned , or the secretaries supp...</td>\n",
       "      <td>The doctors resigned .</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>11495</td>\n",
       "      <td>The artist contacted the banker .</td>\n",
       "      <td>The banker contacted the artist by the student .</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>11496</td>\n",
       "      <td>While the professors arrived , the student wai...</td>\n",
       "      <td>The professors arrived .</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>11497</td>\n",
       "      <td>The banker avoided the author .</td>\n",
       "      <td>The lawyer and the banker avoided the author .</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11498 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Sent1  \\\n",
       "0               0                 U.S., EU Widen Sanctions On Russia   \n",
       "1               1                   The lawyers advised the judges .   \n",
       "2               2  Man kills 4 in Calif. before police shoot him ...   \n",
       "3               3                        Someone is playing a piano.   \n",
       "4               4  In an E-mail statement to the Knoxville News S...   \n",
       "...           ...                                                ...   \n",
       "11493       11493                            A man is playing piano.   \n",
       "11494       11494  The doctors resigned , or the secretaries supp...   \n",
       "11495       11495                  The artist contacted the banker .   \n",
       "11496       11496  While the professors arrived , the student wai...   \n",
       "11497       11497                    The banker avoided the author .   \n",
       "\n",
       "                                                   Sent2  SimScore  \n",
       "0                     U.S., EU Boost Sanctions On Russia      1.00  \n",
       "1      The lawyers advised the judges behind the acto...      0.79  \n",
       "2        Police: Gunman killed 6 in California shootings      0.40  \n",
       "3                             A man is playing a guitar.      0.24  \n",
       "4      I am not giving any consideration to resignati...      0.80  \n",
       "...                                                  ...       ...  \n",
       "11493                     A man is laying on the ground.      0.15  \n",
       "11494                             The doctors resigned .      0.50  \n",
       "11495   The banker contacted the artist by the student .      0.29  \n",
       "11496                           The professors arrived .      0.61  \n",
       "11497     The lawyer and the banker avoided the author .      0.73  \n",
       "\n",
       "[11498 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv('cw2_train.csv')\n",
    "dev_data = pd.read_csv('cw2_dev.csv')\n",
    "train_dataframe = train_data.copy()\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(pos):\n",
    "    if pos.startswith('N'):\n",
    "        return 'n'\n",
    "    elif pos.startswith('V'):\n",
    "        return 'v'\n",
    "    elif pos =='JJ' or pos == 'JJR':\n",
    "        return 'a'\n",
    "    elif pos.startswith('R'):\n",
    "        return 'r'\n",
    "    elif pos == 'JJS':\n",
    "        return 's'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def remove_stopwords(sent_words):\n",
    "    return [ww for ww in sent_words \n",
    "            if ww.lower() not in stop_words and ww not in string.punctuation]\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_result = []\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "for i in np.arange(len(train_data)):\n",
    "    tagged_sent1 = pos_tag(remove_stopwords(word_tokenize(train_dataframe.Sent1[i])))\n",
    "    tagged_sent2 = pos_tag(remove_stopwords(word_tokenize(train_dataframe.Sent2[i])))\n",
    "    train_dataframe.replace(train_dataframe.Sent1[i],' '.join([lemmatizer.lemmatize(k[0]) if pos_tagging(str(k[1]))==None else lemmatizer.lemmatize(k[0],pos_tagging(str(k[1]))) for k in tagged_sent1]),inplace=True)\n",
    "    train_dataframe.replace(train_dataframe.Sent2[i],' '.join([lemmatizer.lemmatize(l[0]) if pos_tagging(str(l[1]))==None else lemmatizer.lemmatize(l[0],pos_tagging(str(l[1]))) for l in tagged_sent2]),inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sent1</th>\n",
       "      <th>Sent2</th>\n",
       "      <th>SimScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. EU Widen Sanctions Russia</td>\n",
       "      <td>U.S. EU Boost Sanctions Russia</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lawyer advise judge</td>\n",
       "      <td>lawyer advise judge behind actor</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Man kill 4 Calif. police shoot dead</td>\n",
       "      <td>Police Gunman kill 6 California shooting</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Someone playing piano</td>\n",
       "      <td>man play guitar</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E-mail statement Knoxville News Sentinel Shuma...</td>\n",
       "      <td>give consideration resignation '' Shumaker say...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11493</th>\n",
       "      <td>11493</td>\n",
       "      <td>man play piano</td>\n",
       "      <td>man lay ground</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>11494</td>\n",
       "      <td>doctor resign secretary support lawyer</td>\n",
       "      <td>doctor resign</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>11495</td>\n",
       "      <td>artist contact banker</td>\n",
       "      <td>banker contact artist student</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>11496</td>\n",
       "      <td>professor arrive student wait</td>\n",
       "      <td>professor arrive</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>11497</td>\n",
       "      <td>banker avoid author</td>\n",
       "      <td>lawyer banker avoid author</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11498 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Sent1  \\\n",
       "0               0                     U.S. EU Widen Sanctions Russia   \n",
       "1               1                                lawyer advise judge   \n",
       "2               2                Man kill 4 Calif. police shoot dead   \n",
       "3               3                              Someone playing piano   \n",
       "4               4  E-mail statement Knoxville News Sentinel Shuma...   \n",
       "...           ...                                                ...   \n",
       "11493       11493                                     man play piano   \n",
       "11494       11494             doctor resign secretary support lawyer   \n",
       "11495       11495                              artist contact banker   \n",
       "11496       11496                      professor arrive student wait   \n",
       "11497       11497                                banker avoid author   \n",
       "\n",
       "                                                   Sent2  SimScore  \n",
       "0                         U.S. EU Boost Sanctions Russia      1.00  \n",
       "1                       lawyer advise judge behind actor      0.79  \n",
       "2               Police Gunman kill 6 California shooting      0.40  \n",
       "3                                        man play guitar      0.24  \n",
       "4      give consideration resignation '' Shumaker say...      0.80  \n",
       "...                                                  ...       ...  \n",
       "11493                                     man lay ground      0.15  \n",
       "11494                                      doctor resign      0.50  \n",
       "11495                      banker contact artist student      0.29  \n",
       "11496                                   professor arrive      0.61  \n",
       "11497                         lawyer banker avoid author      0.73  \n",
       "\n",
       "[11498 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Embeddings\n",
    "In the sample code below, the Glove pre-trained embedding is used. Feel free to use other embeddings if you find it appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-7a3881dfa30c>:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained glove embeddings\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import numpy as np\n",
    "\n",
    "word_vec_dim = 300\n",
    "# specify the loaction of the downloaded glove file\n",
    "path_of_downloaded_files = \"/Users/nithinkyatham/Desktop/MSc AI/2nd Term/NLP CS5990j/env/NLP/cw2-files/glove.6B.{}d.txt\".format(word_vec_dim)\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "\n",
    "oov_vec = np.random.rand(word_vec_dim)\n",
    "\n",
    "def get_sent_word_vecs(word_vectors, sent_words):\n",
    "    vecs = []\n",
    "    for ww in sent_words:\n",
    "        if ww in word_vectors:\n",
    "            vecs.append(word_vectors[ww])\n",
    "        else:\n",
    "            vecs.append(oov_vec)\n",
    "    return np.array(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Sentence Encoder\n",
    "Below, a simple model to create vector representations for sentences is provided. It first computes the average of the words embeddings, and then passes the average embedding to a fully-connected layer and applies a non-linear activation function to generate the final vector. You should develop more advanced models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the baseline model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, embd_dim):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fully_connected_layer = nn.Linear(embd_dim, embd_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fully_connected_layer = nn.Linear(embd_dim, embd_dim)\n",
    "        \n",
    "    def forward(self, sent1_vecs, sent2_vecs):\n",
    "        avg_embd1 = torch.mean(torch.FloatTensor(sent1_vecs), dim=0).unsqueeze(0)\n",
    "        avg_embd2 = torch.mean(torch.FloatTensor(sent2_vecs), dim=0).unsqueeze(0)\n",
    "        sent1_repr = self.relu(self.fully_connected_layer(avg_embd1))\n",
    "        sent2_repr = self.relu(self.fully_connected_layer(avg_embd2))\n",
    "        \n",
    "        return sent1_repr, sent2_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "The function *train_model* below provides a general pipeline for training the sentence encoder model. You could re-use it for training the model you have developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(train_data, n_epochs, lr, optimizer, loss_fnc, model):\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        ep_loss = []\n",
    "        cnt = 0\n",
    "        for i, entry in tqdm(train_data.sample(frac=1).iterrows()):\n",
    "            cnt += 1\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "\n",
    "            # Step 1: Clear the gradients \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Step 2: Compute the forward pass of the model\n",
    "            sent1_repr, sent2_repr = model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "            true_sim = torch.FloatTensor([entry['SimScore']])\n",
    "\n",
    "            # Step 3: Compute the loss value that we wish to optimize\n",
    "            loss = loss_fnc(pred_sim, true_sim)\n",
    "            ep_loss.append(loss.detach())\n",
    "\n",
    "            # Step 4: Propagate the loss signal backward\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 5: Trigger the optimizer to perform one update\n",
    "            optimizer.step()\n",
    "\n",
    "            if  cnt%1000 == 0:\n",
    "                print('epoch {}, avg loss until step {}: {}'.format(epoch_i, cnt, np.mean(ep_loss)))\n",
    "        scheduler.step()\n",
    "        print('\\n======epoch {} loss======'.format(epoch_i),np.mean(ep_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Hyper-Parameters and Start the Training\n",
    "The hyper-parameters and optimizers provided below are just some examples. You should use appropriate strategy to find the hyper-parameters that you want to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c349ac7f924e8583bf0f73b90f1845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703140d64c18462498127c77cade6382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss until step 1000: 0.12439439445734024\n",
      "epoch 0, avg loss until step 2000: 0.12212403863668442\n",
      "epoch 0, avg loss until step 3000: 0.11653298139572144\n",
      "epoch 0, avg loss until step 4000: 0.11326777935028076\n",
      "epoch 0, avg loss until step 5000: 0.11097763478755951\n",
      "epoch 0, avg loss until step 6000: 0.10838763415813446\n",
      "epoch 0, avg loss until step 7000: 0.10662712901830673\n",
      "epoch 0, avg loss until step 8000: 0.10521905869245529\n",
      "epoch 0, avg loss until step 9000: 0.10503815859556198\n",
      "epoch 0, avg loss until step 10000: 0.10353940725326538\n",
      "epoch 0, avg loss until step 11000: 0.10217905789613724\n",
      "\n",
      "\n",
      "======epoch 0 loss====== 0.10176424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130be9074b8d4aad9804aea6fcd8d9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, avg loss until step 1000: 0.0901067778468132\n",
      "epoch 1, avg loss until step 2000: 0.08357927203178406\n",
      "epoch 1, avg loss until step 3000: 0.08091909438371658\n",
      "epoch 1, avg loss until step 4000: 0.08374099433422089\n",
      "epoch 1, avg loss until step 5000: 0.08421073853969574\n",
      "epoch 1, avg loss until step 6000: 0.08319015800952911\n",
      "epoch 1, avg loss until step 7000: 0.08279999345541\n",
      "epoch 1, avg loss until step 8000: 0.0822208970785141\n",
      "epoch 1, avg loss until step 9000: 0.08202027529478073\n",
      "epoch 1, avg loss until step 10000: 0.08200044184923172\n",
      "epoch 1, avg loss until step 11000: 0.08217864483594894\n",
      "\n",
      "\n",
      "======epoch 1 loss====== 0.081853874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel(word_vec_dim)\n",
    "loss_fnc = nn.MSELoss()\n",
    "\n",
    "# hyper parameters\n",
    "n_epochs = 2\n",
    "#lr = 1e-3\n",
    "exp_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "multi_step_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
    "\n",
    "# init optimizer and scheduler (lr adjustor)\n",
    "import torch.optim as optim\n",
    "adam_optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "#swa = optim.swa_utils.SWALR(optimizer,anneal_strategy=\"linear\",swa_lr=0.01)\n",
    "\n",
    "train_model(train_dataframe, n_epochs, multi_step_scheduler, adam_optimizer, loss_fnc, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Adaption and Power Scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerScheduling(lrold,t):\n",
    "    return lrnew=(lrold)/1+t\n",
    "\n",
    "lrAdap = [1,0.1,0.01,0.001,0.0001]\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=powerScheduling(lr,t))\n",
    "\n",
    "train_model(train_dataframe, n_epochs, lr, optimizer, loss_fnc, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Trained Model\n",
    "The function *evaluate_trained_model* defined below tests the performance of a trained model on the dev_set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def evaluate_trained_model(trained_model, dev_data):\n",
    "    pred_scores = []\n",
    "    true_scores = []\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "        model.eval()\n",
    "        for i, entry in tqdm(dev_data.iterrows()):\n",
    "            sent1 = entry['Sent1']\n",
    "            sent2 = entry['Sent2']\n",
    "            gold_score = entry['SimScore']\n",
    "            sent1_embds = get_sent_word_vecs(word_vectors, sent1.split())\n",
    "            sent2_embds = get_sent_word_vecs(word_vectors, sent2.split())\n",
    "            sent1_repr, sent2_repr = trained_model(sent1_embds, sent2_embds)\n",
    "            pred_sim = cos_sim(sent1_repr, sent2_repr)\n",
    "        \n",
    "            pred_scores.append(pred_sim)\n",
    "            true_scores.append(gold_score)\n",
    "\n",
    "    assert len(true_scores) == len(pred_scores)\n",
    "    squared_errors = [np.square(ts-ps) for (ts, ps) in zip(true_scores, pred_scores)]\n",
    "    print('MSE of the method on the dev set:', np.mean(squared_errors))\n",
    "\n",
    "    # check the distribution (histo gram) of the squared errors\n",
    "    plt.hist(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d434325c68a14c19afab8cd3b1888382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE of the method on the dev set: 0.108952515\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_trained_model(model, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model\n",
    "The code below illustrates how to save the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "info_to_save = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'oov_vec': oov_vec\n",
    "}\n",
    "\n",
    "with open('sample_model.state_dict', 'wb') as ff:\n",
    "    pickle.dump(info_to_save, ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
